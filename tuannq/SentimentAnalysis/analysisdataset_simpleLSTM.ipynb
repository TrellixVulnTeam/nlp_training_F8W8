{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/nqtuan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/nqtuan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from tqdm import tqdm\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from bs4 import BeautifulSoup\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import datasetreader\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = datasetreader.readTrain()\n",
    "df_train.head()\n",
    "df_test = datasetreader.readTest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sentiment</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7072</td>\n",
       "      <td>7072</td>\n",
       "      <td>7072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27273</td>\n",
       "      <td>27273</td>\n",
       "      <td>27273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>79582</td>\n",
       "      <td>79582</td>\n",
       "      <td>79582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32927</td>\n",
       "      <td>32927</td>\n",
       "      <td>32927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9206</td>\n",
       "      <td>9206</td>\n",
       "      <td>9206</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           PhraseId  SentenceId  Phrase\n",
       "Sentiment                              \n",
       "0              7072        7072    7072\n",
       "1             27273       27273   27273\n",
       "2             79582       79582   79582\n",
       "3             32927       32927   32927\n",
       "4              9206        9206    9206"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.groupby('Sentiment').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/156060 [00:00<?, ?it/s]/home/nqtuan/.local/lib/python3.6/site-packages/bs4/__init__.py:272: UserWarning: \"b'.'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "100%|██████████| 156060/156060 [00:26<00:00, 5891.64it/s]\n",
      "100%|██████████| 66292/66292 [00:11<00:00, 6018.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156060\n",
      "66292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def clean_sentences(df):\n",
    "    reviews = []\n",
    "\n",
    "    for sent in tqdm(df['Phrase']):\n",
    "        \n",
    "        #remove html content\n",
    "        review_text = BeautifulSoup(sent).get_text()\n",
    "        \n",
    "        #remove non-alphabetic characters\n",
    "        review_text = re.sub(\"[^a-zA-Z]\",\" \", review_text)\n",
    "    \n",
    "        #tokenize the sentences\n",
    "        words = word_tokenize(review_text.lower())\n",
    "    \n",
    "        #lemmatize each word to its lemma\n",
    "        lemma_words = [lemmatizer.lemmatize(i) for i in words]\n",
    "    \n",
    "        reviews.append(lemma_words)\n",
    "\n",
    "    return(reviews)\n",
    "\n",
    "#cleaned reviews for both train and test set retrieved\n",
    "train_sentences = clean_sentences(df_train)\n",
    "test_sentences = clean_sentences(df_test)\n",
    "print(len(train_sentences))\n",
    "print(len(test_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to one-hot vector\n",
    "target = df_train.Sentiment.values\n",
    "y_target = to_categorical(target)\n",
    "num_classes = y_target.shape[1]\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(train_sentences, y_target, test_size=0.2, stratify=y_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 124848/124848 [00:00<00:00, 899753.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13738\n",
      "48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#length of the list of unique_words gives the no of unique words\n",
    "unique_words = set()\n",
    "len_max = 0\n",
    "\n",
    "for sent in tqdm(X_train):\n",
    "    \n",
    "    unique_words.update(sent)\n",
    "    \n",
    "    if(len_max < len(sent)):\n",
    "        len_max = len(sent)\n",
    "\n",
    "print(len(list(unique_words)))\n",
    "print(len_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124848 ['better', 'focused', 'than', 'the', 'incomprehensible', 'anne', 'rice', 'novel'] ['grizzled'] ['mixed', 'up', 'together', 'like', 'a', 'term', 'paper']\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train), X_train[0], X_train[1], X_train[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(124848, 48) (31212, 48) (66292, 48)\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words=len(list(unique_words)))\n",
    "tokenizer.fit_on_texts(list(X_train))\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_val = tokenizer.texts_to_sequences(X_val)\n",
    "X_test = tokenizer.texts_to_sequences(test_sentences)\n",
    "\n",
    "#padding done to equalize the lengths of all input reviews. LSTM networks needs all inputs to be same length.\n",
    "#Therefore reviews lesser than max length will be made equal using extra zeros at end. This is padding.\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=len_max)\n",
    "X_val = sequence.pad_sequences(X_val, maxlen=len_max)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=len_max)\n",
    "print(X_train.shape, X_val.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(124848, 48) [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0  127 3227\n",
      "   32    1 3650 1554 2523  588] [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0 10869] [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0 1177\n",
      "   45  285   34    2  696 1215]\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_train[0], X_train[1], X_train[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/nqtuan/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/nqtuan/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 48, 300)           4121400   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 48, 128)           219648    \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 64)                49408     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               6500      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 505       \n",
      "=================================================================\n",
      "Total params: 4,397,461\n",
      "Trainable params: 4,397,461\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout,Embedding,LSTM\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "early_stopping = EarlyStopping(min_delta = 0.001, mode = 'max', monitor='val_acc', patience = 2)\n",
    "callback = [early_stopping]\n",
    "\n",
    "#Model using Keras LSTM\n",
    "model=Sequential()\n",
    "model.add(Embedding(len(list(unique_words)),300,input_length=len_max))\n",
    "model.add(LSTM(128,dropout=0.5, recurrent_dropout=0.5,return_sequences=True))\n",
    "model.add(LSTM(64,dropout=0.5, recurrent_dropout=0.5,return_sequences=False))\n",
    "model.add(Dense(100,activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes,activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy',optimizer=Adam(lr=0.005),metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/nqtuan/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 124848 samples, validate on 31212 samples\n",
      "Epoch 1/6\n",
      "124848/124848 [==============================] - 154s 1ms/step - loss: 1.0095 - acc: 0.5937 - val_loss: 0.8526 - val_acc: 0.6463\n",
      "Epoch 2/6\n",
      "124848/124848 [==============================] - 153s 1ms/step - loss: 0.8093 - acc: 0.6669 - val_loss: 0.8160 - val_acc: 0.6658\n",
      "Epoch 3/6\n",
      "124848/124848 [==============================] - 144s 1ms/step - loss: 0.7414 - acc: 0.6944 - val_loss: 0.8107 - val_acc: 0.6690\n",
      "Epoch 4/6\n",
      "124848/124848 [==============================] - 139s 1ms/step - loss: 0.6982 - acc: 0.7085 - val_loss: 0.8318 - val_acc: 0.6657\n",
      "Epoch 5/6\n",
      "124848/124848 [==============================] - 142s 1ms/step - loss: 0.6730 - acc: 0.7183 - val_loss: 0.8569 - val_acc: 0.6687\n"
     ]
    }
   ],
   "source": [
    "#This is done for learning purpose only. One can play around with different hyper parameters combinations\n",
    "#and try increase the accuracy even more. For example, a different learning rate, an extra dense layer \n",
    "# before output layer, etc. Cross validation could be used to evaluate the model and grid search \n",
    "# further to find unique combination of parameters that give maximum accuracy. This model has a validation\n",
    "#accuracy of around 66.5%\n",
    "history=model.fit(X_train, y_train, validation_data=(X_val, y_val),epochs=6, batch_size=256, verbose=1, callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create count of the number of epochs\n",
    "epoch_count = range(1, len(history.history['loss']) + 1)\n",
    "\n",
    "# Visualize learning curve. Here learning curve is not ideal. It should be much smoother as it decreases.\n",
    "#As mentioned before, altering different hyper parameters especially learning rate can have a positive impact\n",
    "#on accuracy and learning curve.\n",
    "plt.plot(epoch_count, history.history['loss'], 'r--')\n",
    "plt.plot(epoch_count, history.history['val_loss'], 'b-')\n",
    "plt.legend(['Training Loss', 'Validation Loss'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make the predictions with trained model and submit the predictions.\n",
    "y_pred=model.predict_classes(X_test)\n",
    "\n",
    "sub_file = pd.read_csv('dataset/sampleSubmission.csv',sep=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>156061</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>156062</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>156063</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>156064</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>156065</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>156066</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>156067</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>156068</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>156069</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>156070</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>156071</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>156072</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>156073</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>156074</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>156075</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>156076</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>156077</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>156078</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>156079</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>156080</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>156081</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>156082</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>156083</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>156084</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>156085</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>156086</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>156087</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>156088</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>156089</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>156090</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66262</th>\n",
       "      <td>222323</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66263</th>\n",
       "      <td>222324</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66264</th>\n",
       "      <td>222325</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66265</th>\n",
       "      <td>222326</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66266</th>\n",
       "      <td>222327</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66267</th>\n",
       "      <td>222328</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66268</th>\n",
       "      <td>222329</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66269</th>\n",
       "      <td>222330</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66270</th>\n",
       "      <td>222331</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66271</th>\n",
       "      <td>222332</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66272</th>\n",
       "      <td>222333</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66273</th>\n",
       "      <td>222334</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66274</th>\n",
       "      <td>222335</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66275</th>\n",
       "      <td>222336</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66276</th>\n",
       "      <td>222337</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66277</th>\n",
       "      <td>222338</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66278</th>\n",
       "      <td>222339</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66279</th>\n",
       "      <td>222340</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66280</th>\n",
       "      <td>222341</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66281</th>\n",
       "      <td>222342</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66282</th>\n",
       "      <td>222343</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66283</th>\n",
       "      <td>222344</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66284</th>\n",
       "      <td>222345</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66285</th>\n",
       "      <td>222346</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66286</th>\n",
       "      <td>222347</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66287</th>\n",
       "      <td>222348</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66288</th>\n",
       "      <td>222349</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66289</th>\n",
       "      <td>222350</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66290</th>\n",
       "      <td>222351</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66291</th>\n",
       "      <td>222352</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66292 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       PhraseId  Sentiment\n",
       "0        156061          2\n",
       "1        156062          2\n",
       "2        156063          2\n",
       "3        156064          2\n",
       "4        156065          2\n",
       "5        156066          2\n",
       "6        156067          2\n",
       "7        156068          2\n",
       "8        156069          2\n",
       "9        156070          2\n",
       "10       156071          2\n",
       "11       156072          2\n",
       "12       156073          2\n",
       "13       156074          2\n",
       "14       156075          2\n",
       "15       156076          2\n",
       "16       156077          2\n",
       "17       156078          2\n",
       "18       156079          2\n",
       "19       156080          2\n",
       "20       156081          2\n",
       "21       156082          2\n",
       "22       156083          2\n",
       "23       156084          2\n",
       "24       156085          2\n",
       "25       156086          2\n",
       "26       156087          2\n",
       "27       156088          2\n",
       "28       156089          2\n",
       "29       156090          2\n",
       "...         ...        ...\n",
       "66262    222323          2\n",
       "66263    222324          2\n",
       "66264    222325          2\n",
       "66265    222326          2\n",
       "66266    222327          2\n",
       "66267    222328          2\n",
       "66268    222329          2\n",
       "66269    222330          2\n",
       "66270    222331          2\n",
       "66271    222332          2\n",
       "66272    222333          2\n",
       "66273    222334          2\n",
       "66274    222335          2\n",
       "66275    222336          2\n",
       "66276    222337          2\n",
       "66277    222338          2\n",
       "66278    222339          2\n",
       "66279    222340          2\n",
       "66280    222341          2\n",
       "66281    222342          2\n",
       "66282    222343          2\n",
       "66283    222344          2\n",
       "66284    222345          2\n",
       "66285    222346          2\n",
       "66286    222347          2\n",
       "66287    222348          2\n",
       "66288    222349          2\n",
       "66289    222350          2\n",
       "66290    222351          2\n",
       "66291    222352          2\n",
       "\n",
       "[66292 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66292, 48)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66292"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_file.Sentiment=y_pred\n",
    "sub_file.to_csv('Submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
